# 数据处理

*<u>dataset_info.json</u>*中包含了所有经过预处理的 **本地数据集** 以及 **在线数据集**。如果要使用自定义数据集，需要在 `dataset_info.json` 文件中添加对数据集及其内容的定义

#### 数据集格式

目前支持==Alpaca==格式和==ShareGPT==格式

## 1. Alpaca格式

包括五种任务类型的数据格式：

- 指令监督微调
- 预训练
- 偏好训练
- KTO
- 多模态

### 指令微调数据集

指令监督微调(Instruct Tuning)通过让模型学习详细的指令以及对应的回答来优化模型在特定指令下的表现。

`instruction` 列对应的内容为人类指令， `input` 列对应的内容为人类输入， `output` 列对应的内容为模型回答。下面是一个例子

```
"alpaca_zh_demo.json"
{
  "instruction": "计算这些物品的总费用。 ",
  "input": "输入：汽车 - $3000，衣服 - $100，书 - $20。",
  "output": "汽车、衣服和书的总费用为 $3000 + $100 + $20 = $3120。"
},
```

在进行指令监督微调时， `instruction` 列对应的内容会与 `input` 列对应的内容拼接后作为最终的人类输入，即人类输入为 `instruction\ninput`。而 `output` 列对应的内容为模型回答。 

如果指定， `system` 列对应的内容将被作为系统提示词。

`history` 列是由多个字符串二元组构成的列表，分别代表历史消息中每轮对话的指令和回答。注意在指令监督微调时，历史消息中的回答内容也会被用于模型学习。

指令监督微调数据集 **格式要求** 如下：

```
[
  {
    "instruction": "人类指令（必填）",
    "input": "人类输入（选填）",
    "output": "模型回答（必填）",
    "system": "系统提示词（选填）",
    "history": [
      ["第一轮指令（选填）", "第一轮回答（选填）"],
      ["第二轮指令（选填）", "第二轮回答（选填）"]
    ]
  }
]
```

alpaca 格式 **多轮** 对话的例子，单轮对话只需省略 `history` 列

```
"数据集名称": {
  "file_name": "data.json",
  "columns": {
    "prompt": "instruction",
    "query": "input",
    "response": "output",
    "system": "system",
    "history": "history"
  }
}
```

### 预训练数据集

大语言模型通过学习未被标记的文本进行预训练，从而学习语言的表征。通常，预训练数据集从互联网上获得，因为互联网上提供了大量的不同领域的文本信息，有助于提升模型的泛化能力。 预训练数据集文本描述格式如下：

```
[
  {"text": "document"},
  {"text": "document"}
]
```

在预训练时，只有 `text` 列中的 **内容** （即document）会用于模型学习。

对于上述格式的数据， `dataset_info.json` 中的 **数据集描述** 应为：

```
"数据集名称": {
  "file_name": "data.json",
  "columns": {
    "prompt": "text"
  }
}
```

### 偏好数据集

偏好数据集用于奖励模型训练、DPO 训练和 ORPO 训练。对于系统指令和人类输入，偏好数据集给出了一个更优的回答和一个更差的回答。

[一些研究](https://openai.com/index/instruction-following/) 表明通过让模型学习“什么更好”可以使得模型更加迎合人类的需求。 甚至可以使得参数相对较少的模型的表现优于参数更多的模型。

偏好数据集需要在 `chosen` 列中提供更优的回答，并在 `rejected` 列中提供更差的回答，在一轮问答中其格式如下：

```
[
  {
    "instruction": "人类指令（必填）",
    "input": "人类输入（选填）",
    "chosen": "优质回答（必填）",
    "rejected": "劣质回答（必填）"
  }
]
```

对于上述格式的数据，`dataset_info.json` 中的 **数据集描述** 应为：

```
"数据集名称": {
  "file_name": "data.json",
  "ranking": true,
  "columns": {
    "prompt": "instruction",
    "query": "input",
    "chosen": "chosen",
    "rejected": "rejected"
  }
}
```

### KTO数据集

KTO数据集与偏好数据集类似，但不同于给出一个更优的回答和一个更差的回答，KTO数据集对每一轮问答只给出一个 true/false 的 `label`。 除了 `instruction` 以及 `input` 组成的人类最终输入和模型回答 `output` ，KTO 数据集还需要额外添加一个 `kto_tag` 列（true/false）来表示人类的反馈。

在一轮问答中其格式如下：

```
[
  {
    "instruction": "人类指令（必填）",
    "input": "人类输入（选填）",
    "output": "模型回答（必填）",
    "kto_tag": "人类反馈 [true/false]（必填）"
  }
]
```

对应的 `dataset_info.json` 中的 **数据集描述** 应为：

```
"数据集名称": {
  "file_name": "data.json",
  "columns": {
    "prompt": "instruction",
    "query": "input",
    "response": "output",
    "kto_tag": "kto_tag"
  }
}
```

### 多模态数据集

目前支持的包括：**图像数据集、视频数据集、音频数据集**

#### 图像数据集

多模态图像数据集需要额外添加一个 `images` 列，包含输入图像的路径。 注意图片的数量必须与文本中所有 <image> 标记的数量严格一致。

```
[
  {
    "instruction": "人类指令（必填）",
    "input": "人类输入（选填）",
    "output": "模型回答（必填）",
    "images": [
      "图像路径（必填）"
    ]
  }
]
```

`dataset_info.json` 中数据集描述为：

```
"数据集名称": {
  "file_name": "data.json",
  "columns": {
    "prompt": "instruction",
    "query": "input",
    "response": "output",
    "images": "images"
  }
}
```

#### 视频数据集

类似地，频数据集需要额外添加一个 `videos` 列，包含输入视频的路径。视频的数量必须与文本中所有 <video> 标记的数量严格一致。

```
[
  {
    "instruction": "人类指令（必填）",
    "input": "人类输入（选填）",
    "output": "模型回答（必填）",
    "videos": [
      "视频路径（必填）"
    ]
  }
]
```

对应`dataset_info.json` 中的 **数据集描述** 应为：

```
"数据集名称": {
  "file_name": "data.json",
  "columns": {
    "prompt": "instruction",
    "query": "input",
    "response": "output",
    "videos": "videos"
  }
}
```

#### 音频数据集

音频数据集需要额外添加一个 `audio` 列。

```
[
  {
    "instruction": "人类指令（必填）",
    "input": "人类输入（选填）",
    "output": "模型回答（必填）",
    "audios": [
      "音频路径（必填）"
    ]
  }
]
```

`dataset_info.json` 中的 **数据集描述** 应为：

```
"数据集名称": {
  "file_name": "data.json",
  "columns": {
    "prompt": "instruction",
    "query": "input",
    "response": "output",
    "audios": "audios"
  }
}
```



## ShareGPT格式

不同任务下的数据集格式分为：

- 指令监督微调
- 偏好训练
- OpenAI格式

#### 指令微调数据集

相比 `alpaca` 格式的数据集， `sharegpt` 格式支持 **更多** 的角色种类，例如 human、gpt、observation、function 等等。它们构成一个对象列表呈现在 `conversations` 列中。 下面是 `sharegpt` 格式的一个例子：

```
{
  "conversations": [
    {
      "from": "human",
      "value": "你好，我出生于1990年5月15日。你能告诉我我今天几岁了吗？"
    },
    {
      "from": "function_call",
      "value": "{\"name\": \"calculate_age\", \"arguments\": {\"birthdate\": \"1990-05-15\"}}"
    },
    {
      "from": "observation",
      "value": "{\"age\": 31}"
    },
    {
      "from": "gpt",
      "value": "根据我的计算，你今天31岁了。"
    }
  ],
  "tools": "[{\"name\": \"calculate_age\", \"description\": \"根据出生日期计算年龄\", \"parameters\": {\"type\": \"object\", \"properties\": {\"birthdate\": {\"type\": \"string\", \"description\": \"出生日期以YYYY-MM-DD格式表示\"}}, \"required\": [\"birthdate\"]}}]"}
```

注意其中 human 和 observation 必须出现在奇数位置，gpt 和 function 必须出现在偶数位置。

```
[
  {
    "conversations": [
      {
        "from": "human",
        "value": "人类指令"
      },
      {
        "from": "function_call",
        "value": "工具参数"
      },
      {
        "from": "observation",
        "value": "工具结果"
      },
      {
        "from": "gpt",
        "value": "模型回答"
      }
    ],
    "system": "系统提示词（选填）",
    "tools": "工具描述（选填）"
  }
]
```

`dataset_info.json` 中的 **数据集描述** 应为：

```
"数据集名称": {
  "file_name": "data.json",
  "formatting": "sharegpt",
  "columns": {
    "messages": "conversations",
    "system": "system",
    "tools": "tools"
  }
}
```

### 偏好数据集

Sharegpt 格式的偏好数据集同样需要在 `chosen` 列中提供更优的消息，并在 `rejected` 列中提供更差的消息。 下面是一个例子：

```
{
  "conversations": [
    {
      "from": "human",
      "value": "老虎会吃哪一个，草还是树叶？"
    }
  ],
  "chosen": {
    "from": "gpt",
    "value": "我很高兴能帮助你解答问题！不过，我必须指出，这个问题本身可能没有意义。老虎是食肉动物，通常不吃草或树叶。它们的饮食主要包括大型有蹄动物、小型哺乳动物和鸟类。\n\n如果你提出这个问题是出于好奇或有特定原因，我很乐意帮助你找到更多关于老虎饮食习惯的信息，或者建议资源让你更多了解这些壮丽的生物。请告诉我如何进一步协助你！"
  },
  "rejected": {
    "from": "gpt",
    "value": "一只老虎是食肉动物，这意味着它的饮食主要是肉类。老虎主要猎捕和吃其他动物，如鹿和野猪。它们不会选择吃草或树叶，因为这些不是它们自然饮食的一部分。"
  }
}
```

数据格式为：

```
[
  {
    "conversations": [
      {
        "from": "human",
        "value": "人类指令"
      },
      {
        "from": "gpt",
        "value": "模型回答"
      },
      {
        "from": "human",
        "value": "人类指令"
      }
    ],
    "chosen": {
      "from": "gpt",
      "value": "优质回答"
    },
    "rejected": {
      "from": "gpt",
      "value": "劣质回答"
    }
  }
]
```

`dataset_info.json` 中的 **数据集描述** 应为：

```
"数据集名称": {
  "file_name": "data.json",
  "formatting": "sharegpt",
  "ranking": true,
  "columns": {
    "messages": "conversations",
    "chosen": "chosen",
    "rejected": "rejected"
  }
}
```

### OpenAI格式

OpenAI 格式仅仅是 `sharegpt` 格式的一种特殊情况，其中第一条消息可能是系统提示词

```
[
  {
    "messages": [
      {
        "role": "system",
        "content": "系统提示词（选填）"
      },
      {
        "role": "user",
        "content": "人类指令"
      },
      {
        "role": "assistant",
        "content": "模型回答"
      }
    ]
  }
]
```

`dataset_info.json` 中的 **数据集描述** 应为：

```
"数据集名称": {
  "file_name": "data.json",
  "formatting": "sharegpt",
  "columns": {
    "messages": "messages"
  },
  "tags": {
    "role_tag": "role",
    "content_tag": "content",
    "user_tag": "user",
    "assistant_tag": "assistant",
    "system_tag": "system"
  }
}
```

















