LLaMA-Factory 自定义数据集配置指南

**一、数据集放置位置**
1. 核心目录  
   自定义数据集需存放在 `LLaMA-Factory/data` 目录下。支持以下两种方式：
   • 直接存放：如 `data/custom_data.json`

   • 子目录嵌套：如 `data/finetune/custom_data.json`（需在配置中明确路径）

   • *特殊模型路径*：对于 Qwen2.5-7B 等特定模型，需存放至 `/mnt/workspace/LLaMA-Factory/data`


2. 命名规范  
   • 文件名需与 `dataset_info.json` 中的 `file_name` 字段一致（如 `diy.json`）

   • 避免中文或特殊字符，建议全小写命名


---

**二、配置文件编写（dataset_info.json）**
在 `data/dataset_info.json` 中添加数据集描述，格式如下：
```json
"custom_dataset": {
  "file_name": "custom_data.json",
  "formatting": "alpaca",  // 可选：alpaca（默认）或 sharegpt
  "columns": {
    "prompt": "instruction",  // 指令字段映射
    "query": "input",         // 输入字段映射
    "response": "output",     // 输出字段映射
    "history": "dialog_hist"  // 历史对话字段映射（选填）
  },
  "ranking": false,          // 是否为偏好数据集（用于 DPO/RLHF）
  "tags": {                  // 仅 ShareGPT 格式需配置
    "role_tag": "from",
    "user_tag": "human",
    "assistant_tag": "gpt"
  }
}
```

**关键字段说明**
| 字段         | 作用                     | 允许值                                       |
| ------------ | ------------------------ | -------------------------------------------- |
| `file_name`  | 数据集文件路径           | 相对或绝对路径                               |
| `hf_hub_url` | 从 Hugging Face 加载数据 | 仓库地址（如 `Qwen/Qwen1.5-7B`）             |
| `ms_hub_url` | 从 ModelScope 加载数据   | 仓库地址（如 `damo/nlp_llama`）              |
| `ranking`    | 标识偏好数据集           | `true`（需配合 `chosen` 和 `rejected` 字段） |
| `columns`    | 字段映射规则             | 根据 `formatting` 类型定义键名               |

---

**三、数据格式与字段映射**
1. Alpaca 格式  
   • 适用场景：单轮指令任务（问答、翻译等）

   • 必填字段：`instruction`, `output`

   • 示例：

     ```json
     [{
       "instruction": "翻译为英文",
       "input": "你好",
       "output": "Hello",
       "system": "你是一名翻译助手",
       "history": []
     }]
     ```

2. ShareGPT 格式  
   • 适用场景：多轮对话任务（聊天机器人）

   • 必填字段：`conversations`（包含角色和内容）

   • 示例：

     ```json
     [{
       "conversations": [
         {"from": "human", "value": "你好"},
         {"from": "gpt", "value": "你好！有什么可以帮助您？"}
       ]
     }]
     ```

---

**四、高级配置**
1. 多模态支持  
   • 在 `columns` 中添加 `images` 字段，指定图像路径前缀：

     ```json
     "columns": {
       "images": "image_path"  // 数据中需包含图像路径字段
     }
     ```

2. 远程数据源  
   • 通过 `hf_hub_url` 或 `ms_hub_url` 直接加载云端数据集：

     ```json
     "custom_dataset": {
       "hf_hub_url": "Qwen/Qwen1.5-7B",
       "subset": "train"  // 指定子集
     }
     ```

3. 数据预处理  
   • 添加环境变量强制预处理：

     ```bash
     export OVERWRITE_CACHE=true  # 覆盖旧缓存
     ```

---

**五、常见问题处理**
| 问题         | 解决方案                              | 验证方法                     |
| ------------ | ------------------------------------- | ---------------------------- |
| 数据集未显示 | 检查 `file_name` 路径是否正确         | `jq . data/custom_data.json` |
| 字段映射错误 | 确保 `columns` 键名与数据文件完全匹配 | 对比 JSON 字段与配置         |
| 格式不兼容   | 使用 `alpaca` 或 `sharegpt` 格式      | 参考内置数据集示例           |

> 操作验证：通过内置评估工具 `factory.evaluate()` 或 WebUI 的「预览数据集」功能检查数据加载完整性。