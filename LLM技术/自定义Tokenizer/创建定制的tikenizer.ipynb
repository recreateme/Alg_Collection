{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 1. ​Hugging Face Transformers库"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8bbe728027244d12"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer, models, pre_tokenizers, trainers\n",
    "\n",
    "# 初始化BPE模型\n",
    "tokenizer = Tokenizer(models.BPE())\n",
    "tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel(add_prefix_space=True)\n",
    "\n",
    "# 配置训练参数\n",
    "trainer = trainers.BpeTrainer(\n",
    "    vocab_size=30000,\n",
    "    special_tokens=[\"<unk>\", \"<pad>\", \"<s>\", \"</s>\"]\n",
    ")\n",
    "\n",
    "# 加载语料并训练\n",
    "tokenizer.train(files=[\"corpus.txt\"], trainer=trainer)\n",
    "\n",
    "# 保存\n",
    "tokenizer.save(\"custom_bpe.json\")\n",
    "# 使用时加载\n",
    "Tokenizer.from_file(\"custom_bpe.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. SentencePiece库"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b57544dfb756e983"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "# 配置训练参数\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    input='corpus.txt',\n",
    "    model_prefix='custom_sp',\n",
    "    vocab_size=20000,\n",
    "    model_type='bpe',\n",
    "    character_coverage=0.9995,\n",
    "    pad_id=0,\n",
    "    unk_id=1,\n",
    "    bos_id=2,\n",
    "    eos_id=3\n",
    ")\n",
    "\n",
    "# 加载使用模型\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(\"custom_sp.model\")\n",
    "\n",
    "# 编码示例\n",
    "print(sp.encode_as_pieces(\"自然语言处理\"))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "868480227d6fa81c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. 扩展预训练Tokenizer\n",
    "针对LLM模型添加新token的方法（以LLaMA为例）"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be393d804ca7844d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# 1. 加载基础 tokenizer 和模型\n",
    "# 注意：LLaMA-3-2B 可能需要正确路径或访问权限，假设使用公开模型\n",
    "model_name = \"meta-llama/Llama-3-2B\"  # 替换为实际可用的模型名称\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "except Exception as e:\n",
    "    print(f\"加载模型或tokenizer失败: {e}\")\n",
    "    exit()\n",
    "\n",
    "# 2. 添加自定义标记\n",
    "new_tokens = [\"<think>\", \"</think>\", \"<answer>\", \"</answer>\"]\n",
    "num_new_tokens = tokenizer.add_tokens(new_tokens)\n",
    "print(f\"添加了 {num_new_tokens} 个新标记\")\n",
    "\n",
    "# 3. 调整模型嵌入层大小\n",
    "# 确保嵌入层大小与 tokenizer 的词汇表大小一致\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "print(f\"模型嵌入层已调整为: {model.config.vocab_size}\")\n",
    "\n",
    "# 4. 验证编码效果\n",
    "test_text = \"<think>推理过程</think><answer>最终答案</answer>\"\n",
    "encoded = tokenizer.encode(test_text)\n",
    "print(f\"编码结果: {encoded}\")\n",
    "\n",
    "# 5. （可选）解码验证\n",
    "decoded = tokenizer.decode(encoded)\n",
    "print(f\"解码结果: {decoded}\")\n",
    "\n",
    "# 6. （可选）保存修改后的 tokenizer 和模型\n",
    "output_dir = \"./custom_model\"\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "model.save_pretrained(output_dir)\n",
    "print(f\"已保存到: {output_dir}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d420fd9b957521b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
