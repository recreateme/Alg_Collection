{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-24T11:15:13.399527600Z",
     "start_time": "2025-04-24T11:15:13.369199Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install transformers datasets accelerate peft  # 安装核心库"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "\n",
    "from transformers import (\n",
    "    AutoModel,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForSeq2Seq\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_data(split):\n",
    "    def process(example):\n",
    "        # 训练集处理\n",
    "        if split == \"train\":\n",
    "            instruction = \"分析诗歌《{}[](@replace=10001)》：\\n{}\\n请完成：1.解释关键词 2.翻译全诗 3.识别情感\".format(\n",
    "                example[\"title\"], example[\"content\"]\n",
    "            )\n",
    "            output = {\n",
    "                \"keywords\": example[\"keywords\"],\n",
    "                \"translation\": example[\"trans\"],\n",
    "                \"emotion\": example[\"emotion\"].split(\"、\")[0]\n",
    "            }\n",
    "            return {\"instruction\": instruction, \"input\": \"\", \"output\": json.dumps(output, ensure_ascii=False)}\n",
    "        \n",
    "        # 验证集处理（网页3）\n",
    "        elif split == \"validation\":\n",
    "            instruction = \"请完成以下任务：\\n1.解释词语：{}\\n2.翻译句子：{}\\n3.选择情感：{}\".format(\n",
    "                \"、\".join(example[\"qa_words\"]),\n",
    "                \"；\".join(example[\"qa_sents\"]),\n",
    "                \" | \".join([f\"{k}:{v}\" for k,v in example[\"choose\"].items()])\n",
    "            )\n",
    "            return {\n",
    "                \"instruction\": instruction,\n",
    "                \"input\": f\"《{example['title']}[](@replace=10002)》\\n{example['content']}\",\n",
    "                \"idx\": example[\"idx\"]\n",
    "            }\n",
    "    return process\n",
    "\n",
    "# 自定义数据加载（网页8）\n",
    "def load_custom_data(train_path, val_path):\n",
    "    train_data = load_dataset(\"json\", data_files=train_path, split=\"train\")\n",
    "    val_data = load_dataset(\"json\", data_files=val_path, split=\"train\")\n",
    "    \n",
    "    train_data = train_data.map(preprocess_data(\"train\"), remove_columns=train_data.column_names)\n",
    "    val_data = val_data.map(preprocess_data(\"validation\"), remove_columns=val_data.column_names)\n",
    "    \n",
    "    return train_data, val_data\n",
    "\n",
    "# 模型与分词器初始化（网页2、网页6）    \n",
    "model_name = \"THUDM/chatglm3-6b\"  # 支持中文的轻量级模型\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(\"THUDM/chatglm3-6b\", trust_remote_code=True)\n",
    "\n",
    "# 数据整理器（网页1、网页7）\n",
    "collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer,\n",
    "    padding=True,\n",
    "    max_length=1024,\n",
    "    pad_to_multiple_of=8\n",
    ")\n",
    "\n",
    "# 训练参数（网页4、网页5）\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./output\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=8,\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=3,\n",
    "    fp16=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=200,\n",
    "    logging_steps=50,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=300,\n",
    "    report_to=\"tensorboard\",\n",
    "    gradient_checkpointing=True,  # 显存优化（网页6）\n",
    "    dataloader_num_workers=4,\n",
    "    predict_with_generate=True\n",
    ")\n",
    "\n",
    "# 自定义评估生成（网页3）\n",
    "def generate_predictions(model, tokenizer, val_data):\n",
    "    results = []\n",
    "    for example in val_data:\n",
    "        inputs = tokenizer(\n",
    "            f\"{example['instruction']}\\n{example['input']}\",\n",
    "            return_tensors=\"pt\",\n",
    "            max_length=1024,\n",
    "            truncation=True\n",
    "        ).to(model.device)\n",
    "        \n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=512,\n",
    "            temperature=0.01,\n",
    "            do_sample=False\n",
    "        )\n",
    "        \n",
    "        decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        \n",
    "        # 结果解析（网页1）\n",
    "        try:\n",
    "            json_str = decoded.split(\"{\")[1].split(\"}\")[0]\n",
    "            result = json.loads(\"{\" + json_str + \"}\")\n",
    "        except:\n",
    "            result = {\"ans_qa_words\": {}, \"ans_qa_sents\": {}, \"choose_id\": \"\"}\n",
    "        \n",
    "        results.append({\n",
    "            \"idx\": example[\"idx\"],\n",
    "            **result\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# 训练流程\n",
    "if __name__ == \"__main__\":\n",
    "    # 加载数据\n",
    "    train_data, val_data = load_custom_data(\"train.json\", \"val.json\")\n",
    "    \n",
    "    # 初始化Trainer（网页1、网页3）\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_data,\n",
    "        eval_dataset=val_data,\n",
    "        data_collator=collator,\n",
    "    )\n",
    "    \n",
    "    # 执行训练\n",
    "    trainer.train()\n",
    "    \n",
    "    # 验证集推理\n",
    "    predictions = generate_predictions(trainer.model, tokenizer, val_data)\n",
    "    \n",
    "    # 保存结果\n",
    "    with open(\"predictions.json\", \"w\") as f:\n",
    "        json.dump(predictions, f, indent=2, ensure_ascii=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1378caa22715cbff"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
